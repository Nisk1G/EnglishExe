@ARTICLE{Transformer,
       author = {{Vaswani}, Ashish and {Shazeer}, Noam and {Parmar}, Niki and {Uszkoreit}, Jakob and {Jones}, Llion and {Gomez}, Aidan N. and {Kaiser}, Lukasz and {Polosukhin}, Illia},
        title = "{Attention Is All You Need}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
         year = 2017,
        month = jun,
          eid = {arXiv:1706.03762},
        pages = {arXiv:1706.03762},
archivePrefix = {arXiv},
       eprint = {1706.03762},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170603762V},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
},
@misc{BLEU,
        author  = {TOIN},
        title   = {機械翻訳の評価に最もよく用いられる「BLEUスコア」とは},
        note    = {\url{https://to-in.com/blog/102282}},
        year    = {2020.03.02}
},
@misc{ensemble,
        author = {codExa},
        title  = {機械学習上級者は皆使ってる？！アンサンブル学習の仕組みと3つの種類について解説します},
        note   = {\url{https://www.codexa.net/what-is-ensemble-learning/}},
        year   = {2018.06.21}
}
@misc{LSTM,
        author = {KojiOhki},
        title  = {LSTMネットワークの概要},
        note   = {\url{https://qiita.com/KojiOhki/items/89cd7b69a8a6239d67ca}},
        year   = {2017.12.11},
}

@misc{GRU,
        author = {DeepAge},
        title  = {RNN：時系列データを扱うRecurrent Neural Networksとは},
        note   = {\url{https://deepage.net/deep_learning/2017/05/23/recurrent-neural-networks.html}},
        year   = {2017.05.23}
}